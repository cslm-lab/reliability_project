---
title: "Reliability Analyses"
author: "Pam Fuhrmeister"
date: "`r Sys.Date()`"
output:
  html_document:
    keep_md: yes
    number_sections: yes
    toc: yes
    toc_float: yes
    theme: cosmo
    df_print: kable
---

```{r setup, tidy=TRUE, message=FALSE, comment=""}

# load packages we need
library(tidyverse)
library(ggthemes)
library(brms)
library(tidybayes)
library(posterior)
library(BayesFactor)
library(ggExtra)
library(cowplot)

# set chunk options to show code in output (echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)

# set the width of the code chunk
options(width = 120)

# set the default theme for plots and   
theme_set(theme_few(base_size = 10))

# Uses the computer cores available
options(mc.cores = parallel::detectCores())

# set number of total iterations, warm-up iterations, and chains for the Bayesian models
iter <- 4000
warmup <- 2000
chains <- 4

```


# Experiment 1

In Experiment 1, participants completed a simple picture-naming task (i.e., they saw pictures on a computer screen and were asked to say the name of them aloud) in two different sessions. We tested the split-half reliability in each session as well as the test-retest reliability between sessions. 

## Split-half reliability in Session 1

Read in files for Session 1, filter for correct responses only:

```{r exp1readdata, tidy=TRUE, message=FALSE, comment=""}

# Read in one participant's data to assign column classes to big data frame
test <- read.csv("../data/Experiment1/Session1_ListA/results_5cd49.csv")
colclasses <- sapply(test, typeof)

# make a list of files from session 1 list A
file_names_a <- list.files(path = "../data/Experiment1/Session1_ListA/", 
                         pattern = "*.csv", 
                         full.names = TRUE)

# make a list of files from session 1 list B
file_names_b <- list.files(path = "../data/Experiment1/Session1_ListB/", 
                         pattern = "*.csv", 
                         full.names = TRUE)

# Use map function to iterate over files in list and read them in and assign the correct class to all the columns
df_a <- map_dfr(file_names_a, read.csv, colClasses = colclasses)
df_b <- map_dfr(file_names_b, read.csv, colClasses = colclasses)

# Combine data frames into one big one and filter for correct responses only and positive response times (these two should overlap because answers other than correct got a response time of -1 assigned to them but to be sure I included both)
df <- rbind(df_a, df_b) %>%
  filter(Response_Trial == "correct") %>%
  filter(RT > 0)

# Create a column for even/odd trials
df <- df %>%
  group_by(Participant_ID) %>%
  mutate(TrialType = ifelse(Trial_Nbr %% 2 == 0, "even", "odd"))

```


### Fit model to test split-half reliability in Session 1

```{r, tidy=TRUE, message=FALSE, comment="", cache=TRUE, results='hide'}

# fit Bayesian model predicting response times
# we estimated intercepts for each trial type (even vs. odd) separately rather than an intercept and a slope so we can compute the correlation between response times in the two trial types in the random effects structure

fit_e1_s1_split <- brm(RT ~ 0 + TrialType + (0 + TrialType|Participant_ID) + (1|Target),
              family = lognormal(),
              prior = c(
                prior(normal(6.75, 1.5), class = b),
                prior(normal(0, 1), class = sigma),
                prior(normal(0, 1), class = sd),
                prior(lkj(2), class = cor)
                ),
              iter = iter,
              warmup = warmup,
              data = df
              )

```

### Get estimate of correlation and 95% credible interval

```{r, tidy=TRUE, message=FALSE, comment=""}

fit_e1_s1_split %>%
  spread_draws(cor_Participant_ID__TrialTypeeven__TrialTypeodd) %>%
  mean_hdi(cor_Participant_ID__TrialTypeeven__TrialTypeodd)

```

### Plot density of split-half reliability estimate

```{r, tidy=TRUE, message=FALSE, comment=""}

fit_e1_s1_split %>%
  spread_draws(cor_Participant_ID__TrialTypeeven__TrialTypeodd) %>%
  ggplot(aes(x = cor_Participant_ID__TrialTypeeven__TrialTypeodd,
             fill = stat(abs(x) > .81))) +
  stat_halfeye(.width = 0.95) +
  labs(x = "Correlation between even and odd trials", y = "Density") +
  geom_vline(xintercept = c(.4,.6,.8), linetype = "dashed") +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("skyblue", "gray80")) +
  annotate(geom = "text", x = .18, y = .95, label = "Poor") +
  annotate(geom = "text", x = .5, y = .95, label = "Moderate") +
  annotate(geom = "text", x = .7, y = .95, label = "Good") +
  annotate(geom = "text", x = .9, y = .95, label = "Excellent") +
  scale_x_continuous(breaks = c(0,.4,.6,.8)) +
  coord_cartesian(xlim = c(0, 1))
```

#### Check with frequentist correlation

Just in case we didn't have enough data to estimate the random effect correlations well, we'll test this with a frequentist correlation to make sure the results aren't too different.

```{r, tidy=TRUE, message=FALSE, comment=""}

# create a data frame that computes the mean response time for each participant in each trial type (even and odd trials)
df_sum <- df %>%
  group_by(Participant_ID, TrialType) %>%
  summarize(RT_mean = mean(RT))

# reshape the data frame into wide form
df_sum_wide <- df_sum %>% 
  pivot_wider(names_from = TrialType, values_from = RT_mean)

# compute correlation between even and odd trials
cor.test(df_sum_wide$even, df_sum_wide$odd)

```

#### Plot raw data

```{r, tidy=TRUE, message=FALSE, comment=""}

# scatterplot to show the relationship between response time in even and odd trials
ggplot(df_sum_wide, aes(x = even, y = odd)) + 
  geom_point() +
  geom_smooth(method = "lm") + 
  labs(x = "Response time even trials", y = "Response time odd trials")

```


## Split-half reliability in Session 2

Read in files for Session 2, filter for correct responses only:

```{r, tidy=TRUE, message=FALSE, comment=""}

# Read in one participant's data to assign column classes to big data frame
test_2 <- read.csv("../data/Experiment1/Session2_ListA/results_5cbcc.csv")
colclasses <- sapply(test_2, typeof)

# create list of files for session 2 list A
file_names_a_2 <- list.files(path = "../data/Experiment1/Session2_ListA/", 
                         pattern = "*.csv", 
                         full.names = TRUE)

# create list of files for session 2 list B
file_names_b_2 <- list.files(path = "../data/Experiment1/Session2_ListB/", 
                         pattern = "*.csv", 
                         full.names = TRUE)

# use map function to iterate over files in list, read them in, and assign correct column class to all columns
df_a_2 <- map_dfr(file_names_a_2, read.csv, colClasses = colclasses)
df_b_2 <- map_dfr(file_names_b_2, read.csv, colClasses = colclasses)

# Combine data frames into one big one and filter for correct responses only
df_2 <- rbind(df_a_2, df_b_2) %>%
  filter(Response_Trial == "correct") %>%
  filter(RT > 0)

# Create a column for even/odd trials
df_2 <- df_2 %>%
  group_by(Participant_ID) %>%
  mutate(TrialType = ifelse(Trial_Nbr %% 2 == 0, "even", "odd"))

```

### Fit model to test split-half reliability in Session 2

```{r, tidy=TRUE, message=FALSE, comment="", cache=TRUE, results='hide'}

# fit Bayesian regression model as before
fit_e1_s2_split <- brm(RT ~ 0 + TrialType + (0 + TrialType|Participant_ID) + (1|Target),
              family = lognormal(),
              prior = c(
                prior(normal(6.75, 1.5), class = b),
                prior(normal(0, 1), class = sigma),
                prior(normal(0, 1), class = sd),
                prior(lkj(2), class = cor)
                ),
              iter = iter,
              warmup = warmup,
              data = df_2
              )

```

### Get estimate of correlation and 95% credible interval

```{r, tidy=TRUE, message=FALSE, comment=""}

fit_e1_s2_split %>%
  spread_draws(cor_Participant_ID__TrialTypeeven__TrialTypeodd) %>%
  mean_hdi(cor_Participant_ID__TrialTypeeven__TrialTypeodd)

```

### Plot density of split-half reliability estimate

```{r, tidy=TRUE, message=FALSE, comment=""}

fit_e1_s2_split %>%
  spread_draws(cor_Participant_ID__TrialTypeeven__TrialTypeodd) %>%
  ggplot(aes(x = cor_Participant_ID__TrialTypeeven__TrialTypeodd,
             fill = stat(abs(x) > .81))) +
  stat_halfeye(.width = 0.95) +
  labs(x = "Correlation between even and odd trials", y = "Density") +
  geom_vline(xintercept = c(.4,.6,.8), linetype = "dashed") +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("skyblue", "gray80")) +
  annotate(geom = "text", x = .18, y = .95, label = "Poor") +
  annotate(geom = "text", x = .5, y = .95, label = "Moderate") +
  annotate(geom = "text", x = .7, y = .95, label = "Good") +
  annotate(geom = "text", x = .9, y = .95, label = "Excellent") +
  scale_x_continuous(breaks = c(0,.4,.6,.8)) +
  coord_cartesian(xlim = c(0, 1))

```

#### Check with frequentist correlation

Just in case we didn't have enough data to estimate the random effect correlations well, we'll test this with a frequentist correlation as well.

```{r, tidy=TRUE, message=FALSE, comment=""}

# create data frame with mean response time for each participant in each condition
df_sum_2 <- df_2 %>%
  group_by(Participant_ID, TrialType) %>%
  summarize(RT_mean = mean(RT))

# reshape data frame into wide format
df_sum_wide_2 <- df_sum_2 %>% 
  pivot_wider(names_from = TrialType, values_from = RT_mean)

# compute correlation between even and odd trials
cor.test(df_sum_wide_2$even, df_sum_wide_2$odd)

```

#### Plot raw data

```{r, tidy=TRUE, message=FALSE, comment=""}

# scatterplot to show relationship between response time in even and odd trials
ggplot(df_sum_wide_2, aes(x = even, y = odd)) + 
  geom_point() +
  geom_smooth(method = "lm") + 
  labs(x = "Response time even trials", y = "Response time odd trials")

```

## Test-retest reliability

```{r, tidy=TRUE, message=FALSE, comment=""}

# combine data frames from each session into one big data frame
df_all <- rbind(df, df_2)

# convert the variable session to a factor
df_all$Session <- as.factor(as.character(df_all$Session))

```


### Fit model for test-retest reliability in Experiment 1

```{r, tidy=TRUE, message=FALSE, comment="", cache=TRUE, results='hide'}

# fit Bayesian regression model as before, except with session as fixed effect (still estimating an intercept for each session rather than an intercept and slope for session)
fit_e1_t_rt <- brm(RT ~ 0 + Session + (0 + Session|Participant_ID) + (1|Target),
              family = lognormal(),
              prior = c(
                prior(normal(6.75, 1.5), class = b),
                prior(normal(0, 1), class = sigma),
                prior(normal(0, 1), class = sd),
                prior(lkj(2), class = cor)
                ),
              iter = 10000,
              data = df_all
              )

```

### Get estimate of correlation and 95% credible interval

```{r, tidy=TRUE, message=FALSE, comment=""}

fit_e1_t_rt %>%
  spread_draws(cor_Participant_ID__Session1__Session2) %>%
  mean_hdi(cor_Participant_ID__Session1__Session2)

```

### Plot density of split-half reliability estimate

```{r, tidy=TRUE, message=FALSE, comment=""}

fit_e1_t_rt %>%
  spread_draws(cor_Participant_ID__Session1__Session2) %>%
  ggplot(aes(x = cor_Participant_ID__Session1__Session2,
             fill = stat(abs(x) > .81))) +
  stat_halfeye(.width = 0.95) +
  labs(x = "Correlation between first and second sessions", y = "Density") +
  geom_vline(xintercept = c(.4,.6,.8), linetype = "dashed") +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("gray80", "skyblue")) +
  annotate(geom = "text", x = .18, y = .95, label = "Poor") +
  annotate(geom = "text", x = .5, y = .95, label = "Moderate") +
  annotate(geom = "text", x = .7, y = .95, label = "Good") +
  annotate(geom = "text", x = .9, y = .95, label = "Excellent") +
  scale_x_continuous(breaks = c(0,.4,.6,.8)) +
  coord_cartesian(xlim = c(0, 1))

```

#### Check with frequentist correlation

Just in case we didn't have enough data to estimate the random effect correlations well, we'll test this with a frequentist correlation as well.

```{r, tidy=TRUE, message=FALSE, comment=""}

# create a data frame with mean response time per participant and session
df_sum_3 <- df_all %>%
  group_by(Participant_ID, Session) %>%
  summarize(RT_mean = mean(RT))

# reshape data frame into wide format
df_sum_wide_3 <- df_sum_3 %>% 
  pivot_wider(names_from = Session, values_from = RT_mean)

# compute correlation of response time betweeen the two sessions
cor.test(df_sum_wide_3$`1`, df_sum_wide_3$`2`)

```

#### Plot raw data

```{r, tidy=TRUE, message=FALSE, comment=""}

# scatterplot to show relationship between response time in the two sessions
ggplot(df_sum_wide_3, aes(x = `1`, y = `2`)) + 
  geom_point() +
  geom_smooth(method = "lm") + 
  labs(x = "Response time Session 1", y = "Response time Session 2")

```

### Accuracy Experiment 1

We decided to eliminate participants who did name at least 60% of the pictures correctly. We also want to report the mean and standard deviation of accuracy, so we compute this here.

```{r, tidy=TRUE, message=FALSE, comment=""}

# create a data frame with the number of correct trials (here this is the same as the number of rows in the data frame for that participant at a particular session because we already filtered for correct responses)
acc <- df_all %>%
  group_by(Participant_ID, Session) %>%
  summarize(n = n()) 
  
# we computed each participant's proportion accuracy at each session to see if we need to eliminate them 
# we take the number of rows, n, and divide by 150 (the number of total trials in the experiment)
acc <- acc %>%
  mutate(acc = n/150)

# compute the mean accuracy for each session
acc %>%
  group_by(Session) %>%
  summarize(mean_acc = round(mean(acc),2))

# compute the standard deviation of accuracy for each session
acc %>%
  group_by(Session) %>%
  summarize(sd_acc = round(sd(acc),2))

# count the number of participants in each session that got less than 60% accuracy
# if there are any, we eliminate them from the analyses
acc %>%
  group_by(Session) %>%
    summarize(count = sum(acc < .6))
  

```

# Experiment 2

In Experiment 2, participants completed a simple picture-naming task (i.e., they saw pictures on a computer screen and were asked to say the name of them aloud) and the same task again but with time pressure (i.e., a speeded task).

## Split-half reliability in the non-speeded condition

Read in files for the non-speeded condition filter for correct responses only and for participants who got at least 60% accuracy on the task:

```{r, tidy=TRUE, message=FALSE, comment=""}

# Read in one participant's data to assign column classes to big data frame
test_3 <- read.csv("../data/Experiment2/Exp2_Session1_ListA_NS/results_5bbbc.csv")
colclasses <- sapply(test_3, typeof)

# make a list of files for session 1 list a non-speeded
file_names_1_a_ns <- list.files(path = "../data/Experiment2/Exp2_Session1_ListA_NS/", 
                         pattern = "*.csv", 
                         full.names = TRUE)

# make a list of files for session 2 list a non-speeded
file_names_2_a_ns <- list.files(path = "../data/Experiment2/Exp2_Session2_ListA_NS/", 
                         pattern = "*.csv", 
                         full.names = TRUE)

# make a list of files for session 1 list b non-speeded
file_names_1_b_ns <- list.files(path = "../data/Experiment2/Exp2_Session1_ListB_NS/", 
                         pattern = "*.csv", 
                         full.names = TRUE)

# make a list of files for session 2 list b non-speeded
file_names_2_b_ns <- list.files(path = "../data/Experiment2/Exp2_Session2_ListB_NS/", 
                         pattern = "*.csv", 
                         full.names = TRUE)

# use map function to iterate over lists of files to read them in and assign correct classes for the columns
df_1ans <- map_dfr(file_names_1_a_ns, read.csv, colClasses = colclasses)
df_2ans <- map_dfr(file_names_2_a_ns, read.csv, colClasses = colclasses)
df_1bns <- map_dfr(file_names_1_b_ns, read.csv, colClasses = colclasses)
df_2bns <- map_dfr(file_names_2_b_ns, read.csv, colClasses = colclasses)

# Combine data frames into one big one and filter for correct responses only
df_e2_ns <- rbind(df_1ans, df_2ans, df_1bns, df_2bns) %>%
  filter(Response_Trial == "correct") %>%
  filter(RT > 0) %>%
  filter(Participant_ID != "5fe39") # had less than 60% accuracy

# Create a column for even/odd trials
df_e2_ns <- df_e2_ns %>%
  group_by(Participant_ID) %>%
  mutate(TrialType = ifelse(Trial_Nbr %% 2 == 0, "even", "odd"))

```

### Fit model to test split-half reliability in the non-speeded condition

```{r, tidy=TRUE, message=FALSE, comment="", cache=TRUE, results='hide'}

fit_e2_ns_split <- brm(RT ~ 0 + TrialType + (0 + TrialType|Participant_ID) + (1|Target),
              family = lognormal(),
              prior = c(
                prior(normal(6.75, 1.5), class = b),
                prior(normal(0, 1), class = sigma),
                prior(normal(0, 1), class = sd),
                prior(lkj(2), class = cor)
                ),
              iter = iter,
              warmup = warmup,
              data = df_e2_ns
              )

```

### Get estimate of correlation and 95% credible interval

```{r, tidy=TRUE, message=FALSE, comment=""}

fit_e2_ns_split %>%
  spread_draws(cor_Participant_ID__TrialTypeeven__TrialTypeodd) %>%
  mean_hdi(cor_Participant_ID__TrialTypeeven__TrialTypeodd)

```

### Plot density of split-half reliability estimate

```{r, tidy=TRUE, message=FALSE, comment=""}

fit_e2_ns_split %>%
  spread_draws(cor_Participant_ID__TrialTypeeven__TrialTypeodd) %>%
  ggplot(aes(x = cor_Participant_ID__TrialTypeeven__TrialTypeodd,
             fill = stat(abs(x) > .81))) +
  stat_halfeye(.width = 0.95) +
  labs(x = "Correlation between even and odd trials", y = "Density") +
  geom_vline(xintercept = c(.4,.6,.8), linetype = "dashed") +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("skyblue", "gray80")) +
  annotate(geom = "text", x = .18, y = .95, label = "Poor") +
  annotate(geom = "text", x = .5, y = .95, label = "Moderate") +
  annotate(geom = "text", x = .7, y = .95, label = "Good") +
  annotate(geom = "text", x = .9, y = .95, label = "Excellent") +
  scale_x_continuous(breaks = c(0,.4,.6,.8)) +
  coord_cartesian(xlim = c(0, 1))
```

#### Check with frequentist correlation

Just in case we didn't have enough data to estimate the random effect correlations well, we'll test this with a frequentist correlation to make sure the results aren't too different.

```{r, tidy=TRUE, message=FALSE, comment=""}

df_e2_ns_sum <- df_e2_ns %>%
  group_by(Participant_ID, TrialType) %>%
  summarize(RT_mean = mean(RT))


df_e2_ns_sum_wide <- df_e2_ns_sum %>% 
  pivot_wider(names_from = TrialType, values_from = RT_mean)

cor.test(df_e2_ns_sum_wide$even, df_e2_ns_sum_wide$odd)

```

#### Plot raw data

```{r, tidy=TRUE, message=FALSE, comment=""}

ggplot(df_e2_ns_sum_wide, aes(x = even, y = odd)) + 
  geom_point() +
  geom_smooth(method = "lm") + 
  labs(x = "Response time even trials", y = "Response time odd trials")

```

## Split-half reliability in the speeded condition

Read in files for the speeded condition filter for correct responses only and for participants who got at least 60% accuracy on the task:

```{r, tidy=TRUE, message=FALSE, comment=""}

# Read in one participant's data to assign column classes to big data frame
test_4 <- read.csv("../data/Experiment2/Exp2_Session1_ListA_S/results_5f31a.csv")
colclasses <- sapply(test_4, typeof)

file_names_1_a_s <- list.files(path = "../data/Experiment2/Exp2_Session1_ListA_S/", 
                         pattern = "*.csv", 
                         full.names = TRUE)

file_names_1_b_s <- list.files(path = "../data/Experiment2/Exp2_Session1_ListB_S/", 
                         pattern = "*.csv", 
                         full.names = TRUE)

file_names_2_a_s <- list.files(path = "../data/Experiment2/Exp2_Session2_ListA_S/", 
                         pattern = "*.csv", 
                         full.names = TRUE)

file_names_2_b_s <- list.files(path = "../data/Experiment2/Exp2_Session2_ListB_S/", 
                         pattern = "*.csv", 
                         full.names = TRUE)

df_1as <- map_dfr(file_names_1_a_s, read.csv, colClasses = colclasses)
df_1bs <- map_dfr(file_names_1_b_s, read.csv, colClasses = colclasses)
df_2as <- map_dfr(file_names_2_a_s, read.csv, colClasses = colclasses)
df_2bs <- map_dfr(file_names_2_b_s, read.csv, colClasses = colclasses)

# Combine data frames into one big one and filter for correct responses only
df_e2_s <- rbind(df_1as, df_1bs, df_2as, df_2bs) %>%
  filter(Response_Trial == "correct") %>%
  filter(RT > 0) %>%
  filter(Participant_ID != "5fe39") %>% # had less than 60% accuracy
  filter(Participant_ID != "6154b") # data didn't get saved--technical error

# Create a column for even/odd trials
df_e2_s <- df_e2_s %>%
  group_by(Participant_ID) %>%
  mutate(TrialType = ifelse(Trial_Nbr %% 2 == 0, "even", "odd"))

```

### Fit model to test split-half reliability in Session 1

```{r, tidy=TRUE, message=FALSE, comment="", cache=TRUE, results='hide'}

fit_e2_s_split <- brm(RT ~ 0 + TrialType + (0 + TrialType|Participant_ID) + (1|Target),
              family = lognormal(),
              prior = c(
                prior(normal(6.75, 1.5), class = b),
                prior(normal(0, 1), class = sigma),
                prior(normal(0, 1), class = sd),
                prior(lkj(2), class = cor)
                ),
              iter = iter,
              warmup = warmup,
              data = df_e2_s
              )

```

### Get estimate of correlation and 95% credible interval

```{r, tidy=TRUE, message=FALSE, comment=""}

fit_e2_s_split %>%
  spread_draws(cor_Participant_ID__TrialTypeeven__TrialTypeodd) %>%
  mean_hdi(cor_Participant_ID__TrialTypeeven__TrialTypeodd)

```

### Plot density of split-half reliability estimate

```{r, tidy=TRUE, message=FALSE, comment=""}

fit_e2_s_split %>%
  spread_draws(cor_Participant_ID__TrialTypeeven__TrialTypeodd) %>%
  ggplot(aes(x = cor_Participant_ID__TrialTypeeven__TrialTypeodd,
             fill = stat(abs(x) > .81))) +
  stat_halfeye(.width = 0.95) +
  labs(x = "Correlation between even and odd trials", y = "Density") +
  geom_vline(xintercept = c(.4,.6,.8), linetype = "dashed") +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("skyblue", "gray80")) +
  annotate(geom = "text", x = .18, y = .95, label = "Poor") +
  annotate(geom = "text", x = .5, y = .95, label = "Moderate") +
  annotate(geom = "text", x = .7, y = .95, label = "Good") +
  annotate(geom = "text", x = .9, y = .95, label = "Excellent") +
  scale_x_continuous(breaks = c(0,.4,.6,.8)) +
  coord_cartesian(xlim = c(0, 1))
```

#### Check with frequentist correlation

Just in case we didn't have enough data to estimate the random effect correlations well, we'll test this with a frequentist correlation to make sure the results aren't too different.

```{r, tidy=TRUE, message=FALSE, comment=""}

df_e2_s_sum <- df_e2_s %>%
  group_by(Participant_ID, TrialType) %>%
  summarize(RT_mean = mean(RT))


df_e2_s_sum_wide <- df_e2_s_sum %>% 
  pivot_wider(names_from = TrialType, values_from = RT_mean)

cor.test(df_e2_s_sum_wide$even, df_e2_s_sum_wide$odd)

```

#### Plot raw data

```{r, tidy=TRUE, message=FALSE, comment=""}

ggplot(df_e2_s_sum_wide, aes(x = even, y = odd)) + 
  geom_point() +
  geom_smooth(method = "lm") + 
  labs(x = "Response time even trials", y = "Response time odd trials")

```

## Correlation between conditions (speeded and non-speeded)

```{r, tidy=TRUE, message=FALSE, comment=""}

df_all_e2 <- rbind(df_e2_ns, df_e2_s)

df_all_e2 <- df_all_e2 %>%
  mutate(Type_Trial = 
           case_when(
             Type_Trial == "naming" ~ "nonspeeded",
             Type_Trial == "peeded" ~ "speeded"
             )
  )

df_all_e2$Type_Trial <- as.factor(as.character(df_all_e2$Type_Trial))

```


### Fit model for reliability over conditions in Experiment 2

```{r, tidy=TRUE, message=FALSE, comment="", cache=TRUE, results='hide'}

fit_e2_s_ns <- brm(RT ~ 0 + Type_Trial + (0 + Type_Trial|Participant_ID) + (1|Target),
              family = lognormal(),
              prior = c(
                prior(normal(6.75, 1.5), class = b),
                prior(normal(0, 1), class = sigma),
                prior(normal(0, 1), class = sd),
                prior(lkj(2), class = cor)
                ),
              iter = 10000,
              warmup = warmup,
              data = df_all_e2
              )

```

### Get estimate of correlation and 95% credible interval

```{r, tidy=TRUE, message=FALSE, comment=""}

fit_e2_s_ns %>%
  spread_draws(cor_Participant_ID__Type_Trialnonspeeded__Type_Trialspeeded) %>%
  mean_hdi(cor_Participant_ID__Type_Trialnonspeeded__Type_Trialspeeded)

```

### Plot density of estimate

```{r, tidy=TRUE, message=FALSE, comment=""}

fit_e2_s_ns %>%
  spread_draws(cor_Participant_ID__Type_Trialnonspeeded__Type_Trialspeeded) %>%
  ggplot(aes(x = cor_Participant_ID__Type_Trialnonspeeded__Type_Trialspeeded,
             fill = stat(abs(x) > .81))) +
  stat_halfeye(.width = 0.95) +
  labs(x = "Correlation between speeded and non-speeded conditions", y = "Density") +
  geom_vline(xintercept = c(.4,.6,.8), linetype = "dashed") +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("gray80", "skyblue")) +
  annotate(geom = "text", x = .18, y = .95, label = "Poor") +
  annotate(geom = "text", x = .5, y = .95, label = "Moderate") +
  annotate(geom = "text", x = .7, y = .95, label = "Good") +
  annotate(geom = "text", x = .9, y = .95, label = "Excellent") +
  scale_x_continuous(breaks = c(0,.4,.6,.8)) +
  coord_cartesian(xlim = c(0, 1))

```

#### Check with frequentist correlation

Just in case we didn't have enough data to estimate the random effect correlations well, we'll test this with a frequentist correlation as well.

```{r, tidy=TRUE, message=FALSE, comment=""}

df_sum_e2 <- df_all_e2 %>%
  group_by(Participant_ID, Type_Trial) %>%
  summarize(RT_mean = mean(RT))


df_sum_wide_e2 <- df_sum_e2 %>% 
  pivot_wider(names_from = Type_Trial, values_from = RT_mean)

cor.test(df_sum_wide_e2$nonspeeded, df_sum_wide_e2$speeded)

```

#### Plot raw data

```{r, tidy=TRUE, message=FALSE, comment=""}

ggplot(df_sum_wide_e2, aes(x = nonspeeded, y = speeded)) + 
  geom_point() +
  geom_smooth(method = "lm") + 
  labs(x = "Response time non-speeded condition", y = "Response time speeded condition")

```

### Accuracy Experiment 2

We decided to eliminate participants who did name at least 60% of the pictures correctly. We also want to report the mean and standard deviation of accuracy, so we compute this here.

```{r, tidy=TRUE, message=FALSE, comment=""}

acc_e2 <- df_all_e2 %>%
  group_by(Participant_ID, Type_Trial) %>%
  summarize(n = n()) 
  
acc_e2 <- acc_e2 %>%
  mutate(acc = n/150)

acc_e2 %>%
  group_by(Type_Trial) %>%
  summarize(mean_acc = round(mean(acc),2))

acc_e2 %>%
  group_by(Type_Trial) %>%
  summarize(sd_acc = round(sd(acc),2))

acc_e2 %>%
  group_by(Type_Trial) %>%
    summarize(count = sum(acc < .6))
  

```

## Speed-accuracy tradeoff

```{r, tidy=TRUE, message=FALSE, comment=""}

accuracy <- rbind(df_1ans, df_2ans, df_1bns, df_2bns, 
                  df_1as, df_2as, df_1bs, df_2bs)

accuracy <- accuracy %>%
  mutate(acc = ifelse(Response_Trial == "correct", 1, 0)) %>%
  filter(Participant_ID != "5fe39") %>% # less than 60% correct
  mutate(Type_Trial = 
           case_when(
             Type_Trial == "naming" ~ "nonspeeded",
             Type_Trial == "peeded" ~ "speeded"
             )
  )

accuracy$Type_Trial <- as.factor(as.character(accuracy$Type_Trial))

```


```{r, tidy=TRUE, message=FALSE, comment="", cache=TRUE, results='hide'}

fit_e2_acc <- brm(acc ~ 0 + Type_Trial + (0 + Type_Trial|Participant_ID) + (1|Target),
              family = bernoulli(),
              prior = c(
                prior(normal(0, 1.5), class = b),
                prior(normal(0, 1), class = sd),
                prior(lkj(2), class = cor)
                ),
              iter = iter,
              warmup = warmup,
              data = accuracy
              )

```


Extract group level estimates from accuracy and RT models

```{r, tidy=TRUE, message=FALSE, comment=""}

acc_ns <- data.frame(coef(fit_e2_acc)$Participant_ID[,,1][,1])
acc_s <- data.frame(coef(fit_e2_acc)$Participant_ID[,,2][,1])
rt_ns <- data.frame(coef(fit_e2_s_ns)$Participant_ID[,,1][,1])
rt_s <- data.frame(coef(fit_e2_s_ns)$Participant_ID[,,2][,1])

acc_ns$Participant_ID <- rownames(acc_ns)
colnames(acc_ns)[1] <- "acc_ns"
acc_s$Participant_ID <- rownames(acc_s)
colnames(acc_s)[1] <- "acc_s"
rt_ns$Participant_ID <- rownames(rt_ns)
colnames(rt_ns)[1] <- "rt_ns"
rt_s$Participant_ID <- rownames(rt_s)
colnames(rt_s)[1] <- "rt_s"

acc_rt <- merge(merge(merge(
  acc_ns, 
  acc_s,),
  rt_ns,),
  rt_s, 
  by = "Participant_ID")

```

Compute correlations

```{r, tidy=TRUE, message=FALSE, comment=""}

corr_ns <- correlationBF(acc_rt$rt_ns, acc_rt$acc_ns)
bayestestR::describe_posterior(corr_ns, centrality = "mean")
cor.test(acc_rt$rt_ns, acc_rt$acc_ns)

corr_s <- correlationBF(acc_rt$rt_s, acc_rt$acc_s)
bayestestR::describe_posterior(corr_s, centrality = "mean")
cor.test(acc_rt$rt_s, acc_rt$acc_s)

```

```{r, tidy=TRUE, message=FALSE, comment="", fig.dim = c(9, 3.5)}

corr_ns_plot <- ggplot(acc_rt, aes(rt_ns, acc_ns)) +
  geom_point(color = "#440154FF", alpha = .5, size = 5) +
  geom_smooth(method = "lm", size = .5, color = "black") +
  labs(x = "", y = "Picture naming accuracy\n")

corr_ns_plot_mh <- ggMarginal(corr_ns_plot, type = "histogram")

corr_s_plot <- ggplot(acc_rt, aes(rt_s, acc_s)) +
  geom_point(color = "#440154FF", alpha = .5, size = 5) +
  geom_smooth(method = "lm", size = .5, color = "black") +
  labs(x = "", y = "")

corr_s_plot_mh <- ggMarginal(corr_s_plot, type = "histogram")

plot_row <- plot_grid(corr_ns_plot_mh, corr_s_plot_mh, 
                      labels = c("Non-speeded", "Speeded"), 
                      align = "hv")

 xlabel <- ggdraw() + 
  draw_label(
    "Picture naming response time",
    size = 12
  ) 

plot_grid(
  plot_row, xlabel,
  nrow = 2,
  rel_heights = c(1, 0.05)
)

```